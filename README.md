# HFHI-virtual-policy-marker
Lightweight toolkit to label CRS (Creditor Reporting System) entries for an "adequate housing" virtual policy marker and run final analyses.

## Repository layout

- `code/` — main scripts (Python + R) used for data download, preprocessing, labeling, merging and analysis.
- `large_input/` — raw and intermediate large CSVs (CRS yearly files, collated datasets).
- `large_output/` — labeled and merged datasets produced by the pipeline.
- `output/` — analysis tables and plots generated by the R analysis scripts.

## Streamlined code overview

The `code/` folder was simplified and now contains a small set of clear-stage scripts:

- `code/1.0_download_crs.py` — download and collate CRS yearly files into `large_input/`.
- `code/2.0_preprocess_crs.py` — preprocess and clean collated CRS data; build the text field used for labeling.
- `code/3.0_gpt_label.py` — run LLM-based labeling (configurable backend) to produce label CSVs.
- `code/4.0_merge.py` — merge label outputs back into the original dataset and write results to `large_output/`.
- `code/5.0_virtual_policy_marker_analysis.R` and `code/5.0_virtual_policy_marker_analysis_wb.R` — generate figures and tables summarizing the virtual policy marker (WB variant included).
- `code/common.py` — shared helper functions and utilities.
- `code/hfhi_definitions.py`, `code/wb_definitions.py` — concept and keyword definitions used by scripts.

## Quick start

1. Install Python dependencies (see `requirements.txt`) and required R packages for analysis.
2. Run the pipeline stages you need, for example:

```bash
python code/1.0_download_crs.py
python code/2.0_preprocess_crs.py
python code/3.0_gpt_label.py
python code/4.0_merge.py
Rscript code/5.0_virtual_policy_marker_analysis.R
```

Check the top of each script for configurable constants (file paths, SUFFIX, API/back-end selection).

## Data locations

- Input raw and intermediate files: `large_input/`
- Labeled and merged outputs: `large_output/`
- Analysis outputs (tables/plots): `output/`
